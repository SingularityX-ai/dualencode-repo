
<!DOCTYPE html>
<html>
<head>
    <script src="https://unpkg.com/vis-network@9.1.9/standalone/umd/vis-network.min.js"></script>
    <style>
        #mindmap {
            width: 100%;
            height: 800px;
            border: 1px solid lightgray;
        }
    </style>
</head>
<body>
    <div id="mindmap"></div>
    <script>


        const nodes = new vis.DataSet([{'id': 'root', 'label': 'Code Repository', 'level': 0}, {'id': 'cluster_0', 'label': 'get_related', 'level': 1}, {'id': 'get_api_key', 'label': 'get_api_key', 'level': 2, 'title': ''}, {'id': 'load_locales', 'label': 'load_locales', 'level': 2, 'title': ''}, {'id': 'get_system_locale', 'label': 'get_system_locale', 'level': 2, 'title': ''}, {'id': 'cluster_1', 'label': 'video_related', 'level': 1}, {'id': 'generate_video_script', 'label': 'generate_video_script', 'level': 2, 'title': ''}, {'id': 'search_videos_pixabay', 'label': 'search_videos_pixabay', 'level': 2, 'title': ''}, {'id': 'save_video', 'label': 'save_video', 'level': 2, 'title': ''}, {'id': 'search_videos_pexels', 'label': 'search_videos_pexels', 'level': 2, 'title': ''}, {'id': 'download_videos', 'label': 'download_videos', 'level': 2, 'title': ''}, {'id': 'file_to_subtitles', 'label': 'file_to_subtitles', 'level': 2, 'title': ''}, {'id': 'stream_video', 'label': 'stream_video', 'level': 2, 'title': ''}, {'id': 'generate_video_terms', 'label': 'generate_video_terms', 'level': 2, 'title': ''}, {'id': 'delete_video', 'label': 'delete_video', 'level': 2, 'title': ''}, {'id': 'file_iterator', 'label': 'file_iterator', 'level': 2, 'title': ''}, {'id': 'cluster_2', 'label': 'save_related', 'level': 1}, {'id': 'save_config', 'label': 'save_config', 'level': 2, 'title': ''}, {'id': 'file_to_uri', 'label': 'file_to_uri', 'level': 2, 'title': ''}, {'id': 'cluster_3', 'label': 'check_related', 'level': 1}, {'id': 'check_queue', 'label': 'check_queue', 'level': 2, 'title': ''}, {'id': 'verify_token', 'label': 'verify_token', 'level': 2, 'title': ''}, {'id': 'cluster_4', 'label': '_related', 'level': 1}, {'id': 'levenshtein_distance', 'label': 'levenshtein_distance', 'level': 2, 'title': ''}, {'id': 'correct', 'label': 'correct', 'level': 2, 'title': ''}, {'id': 'load_config', 'label': 'load_config', 'level': 2, 'title': ''}, {'id': '__init_logger', 'label': '__init_logger', 'level': 2, 'title': ''}, {'id': 'serialize', 'label': 'serialize', 'level': 2, 'title': ''}, {'id': 'format_record', 'label': 'format_record', 'level': 2, 'title': ''}, {'id': 'to_json', 'label': 'to_json', 'level': 2, 'title': ''}, {'id': '_do', 'label': '_do', 'level': 2, 'title': ''}, {'id': 'add_task', 'label': 'add_task', 'level': 2, 'title': ''}, {'id': 'match_line', 'label': 'match_line', 'level': 2, 'title': ''}, {'id': 'create', 'label': 'create', 'level': 2, 'title': ''}, {'id': 'create_task', 'label': 'create_task', 'level': 2, 'title': ''}, {'id': 'split_string_by_punctuations', 'label': 'split_string_by_punctuations', 'level': 2, 'title': ''}, {'id': 'cluster_5', 'label': 'generate_related', 'level': 1}, {'id': 'create_subtitle', 'label': 'create_subtitle', 'level': 2, 'title': '"""\n    优化字幕文件\n    1. 将字幕文件按照标点符号分割成多行\n    2. 逐行匹配字幕文件中的文本\n    3. 生成新的字幕文件'}, {'id': 'format_response', 'label': 'format_response', 'level': 2, 'title': '"""Format a response by cleaning and selecting paragraphs.\n\n        This function takes a response string, removes specific characters such\n        as asterisks and hashes, and eliminates markdown syntax. It then splits\n        the cleaned response into paragraphs and selects a specified number of\n        paragraphs to return as a single string.\n\n        Args:\n            response (str): The input response string to be formatted.\n\n        Returns:\n            str: The formatted response containing the selected paragraphs.'}, {'id': 'preprocess_video', 'label': 'preprocess_video', 'level': 2, 'title': '"""Preprocess a list of video and image materials.\n\n    This function iterates through a list of materials, checking each\n    material\'s URL. If the URL is valid, it attempts to create a video clip\n    from the URL. If the creation fails, it tries to create an image clip\n    instead. The function checks the dimensions of the clip and logs a\n    warning if the dimensions are smaller than 480 pixels. For image\n    materials, it creates a zoom effect and outputs the processed video as\n    an MP4 file. The processed materials are updated with the new video\n    URLs.\n\n    Args:\n        materials (List[MaterialInfo]): A list of MaterialInfo objects containing URLs\n            to video or image files.\n        clip_duration (int?): The duration of the clips in seconds. Defaults to 4.\n\n    Returns:\n        List[MaterialInfo]: The updated list of materials with new video URLs.'}, {'id': '_generate_response', 'label': '_generate_response', 'level': 2, 'title': '"""Generate a response from a specified language model provider.\n\n    This function takes a user prompt and interacts with various language\n    model providers (such as OpenAI, G4F, Moonshot, Ollama, Gemini, etc.) to\n    generate a response. It retrieves the necessary configuration settings\n    (like API keys, model names, and base URLs) from the application\n    configuration. Depending on the selected provider, it constructs the\n    appropriate request and processes the response to return the generated\n    content.\n\n    Args:\n        prompt (str): The input prompt for which a response is to be generated.\n\n    Returns:\n        str: The generated response content from the language model.\n\n    Raises:\n        ValueError: If required configuration values such as `api_key`, `model_name`, or\n            `base_url`\n            are not set in the configuration.\n        Exception: If the response from the language model provider is invalid or empty.'}, {'id': 'save_script_data', 'label': 'save_script_data', 'level': 2, 'title': '"""Save video script data to a JSON file.\n\n    This function creates a JSON file containing the video script, search\n    terms, and additional parameters associated with a specific task. The\n    JSON file is saved in the task directory, which is determined by the\n    provided task ID.\n\n    Args:\n        task_id (str): The identifier for the task.\n        video_script (str): The video script to be saved.\n        video_terms (list): A list of search terms related to the video.\n        params (dict): Additional parameters to be included in the script data.'}, {'id': 'update_task', 'label': 'update_task', 'level': 2, 'title': '"""Update the state and progress of a task in the Redis database.\n\n        This function updates the specified task\'s state and progress in the\n        Redis database. It ensures that the progress value does not exceed 100\n        and allows for additional fields to be updated through keyword\n        arguments.\n\n        Args:\n            task_id (str): The unique identifier of the task to be updated.\n            state (int?): The new state of the task. Defaults to\n                const.TASK_STATE_PROCESSING.\n            progress (int?): The current progress of the task,\n                represented as a percentage. Defaults to 0.\n            **kwargs: Additional fields to update in the task.'}, {'id': 'get_application', 'label': 'get_application', 'level': 2, 'title': '"""Initialize a FastAPI application.\n\n    This function creates and configures an instance of a FastAPI\n    application. It sets the title, description, and version of the\n    application based on the provided configuration. Additionally, it\n    includes a router for handling API requests and adds exception handlers\n    for specific exceptions.\n\n    Returns:\n        FastAPI: An instance of the FastAPI application.'}, {'id': 'get_text_size', 'label': 'get_text_size', 'level': 2, 'title': '"""Get the size of the given text.\n\n        This function calculates the bounding box of the provided text using the\n        current font settings. It returns the width and height of the text by\n        determining the difference between the left and right edges, and the top\n        and bottom edges of the bounding box.\n\n        Args:\n            inner_text (str): The text for which to calculate the size.\n\n        Returns:\n            tuple: A tuple containing the width and height of the text.'}, {'id': '_convert_to_original_type', 'label': '_convert_to_original_type', 'level': 2, 'title': '"""Convert the value from byte string to its original data type.\n\n        This function attempts to decode a byte string into its original\n        representation. It first decodes the byte string to a UTF-8 string and\n        then tries to evaluate it as a Python literal. If the evaluation fails,\n        it checks if the string represents an integer and converts it\n        accordingly. Additional data type conversions can be added as needed.\n\n        Args:\n            value (bytes): The byte string to be converted.\n\n        Returns:\n            The original data type of the input value, which could be a list,\n            integer, or string.'}, {'id': 'generate_script', 'label': 'generate_script', 'level': 2, 'title': '"""Generate a video script based on the specified subject.\n\n    This function creates a script for a video by utilizing a prompt that\n    outlines the role of a video script generator. The script is generated\n    according to the specified subject and can be customized by the number\n    of paragraphs and language. The function ensures that the output adheres\n    to specific constraints, such as avoiding any markdown or formatting and\n    not referencing the prompt in the response.\n\n    Args:\n        video_subject (str): The subject of the video for which the script is generated.\n        language (str?): The language in which the script should be generated. Defaults to an\n            empty string.\n        paragraph_number (int?): The number of paragraphs to include in the script. Defaults to 1.\n\n    Returns:\n        str: The generated video script as a plain string.\n\n    Raises:\n        ValueError: If the generated script contains an error message indicating that the\n            daily quota has been exhausted.'}, {'id': 'create_text_clip', 'label': 'create_text_clip', 'level': 2, 'title': '"""Create a text clip for subtitles in a video.\n\n        This function generates a text clip from a given subtitle item. It wraps\n        the text to fit within a specified maximum width and applies various\n        styling options such as font, size, color, and position. The duration of\n        the clip is determined by the start and end times provided in the\n        subtitle item. The function also handles positioning the text clip based\n        on user-defined parameters, ensuring that it appears correctly on the\n        screen.\n\n        Args:\n            subtitle_item (tuple): A tuple containing two elements:\n                - A tuple with start and end times (float, float) for the subtitle.\n                - A string representing the subtitle text.\n\n        Returns:\n            TextClip: A moviepy TextClip object configured with the wrapped text and specified\n                properties.'}, {'id': 'get_video_materials', 'label': 'get_video_materials', 'level': 2, 'title': '"""Retrieve video materials based on the specified parameters.\n\n    This function processes video materials either from a local source or by\n    downloading them from a specified video source. If the video source is\n    local, it preprocesses the provided materials and returns their URLs. If\n    the source is remote, it attempts to download videos based on the\n    provided search terms and parameters. In case of failure to find valid\n    materials or download videos, it updates the task state to failed and\n    logs an error message.\n\n    Args:\n        task_id (str): The identifier for the task being processed.\n        params (object): An object containing various parameters including video source,\n            materials, and durations.\n        video_terms (list): A list of terms used for searching videos if downloading from a remote\n            source.\n        audio_duration (int): The duration of the audio to be used in the video processing.\n\n    Returns:\n        list or None: A list of URLs of the processed video materials if\n            successful, otherwise None.'}, {'id': 'wrap_text', 'label': 'wrap_text', 'level': 2, 'title': '"""Wrap text to fit within a specified width.\n\n    This function takes a string of text and wraps it so that each line does\n    not exceed the specified maximum width. It uses a specified font and\n    font size to calculate the width of the text. If the text fits within\n    the maximum width, it is returned as is. If it does not fit, the text is\n    split into multiple lines that fit within the specified width. The\n    height of the resulting text block is also calculated based on the\n    number of lines.\n\n    Args:\n        text (str): The text to be wrapped.\n        max_width (int): The maximum width of each line in pixels.\n        font (str?): The font type to use for rendering the text. Defaults to "Arial".\n        fontsize (int?): The size of the font to use for rendering the text. Defaults to 60.\n\n    Returns:\n        tuple: A tuple containing the wrapped text as a string and the height of the\n            resulting text block in pixels.'}, {'id': 'toogle_openai_usage', 'label': 'toogle_openai_usage', 'level': 2, 'title': '"""Toggles the usage of OpenAI service.\n\n    This function checks the current usage status of OpenAI service, toggles\n    it to the opposite value, and updates the status in the Redis database.\n    It then logs the action and sends a message to Slack about the change.\n\n    Returns:\n        bool: The updated usage status after toggling.'}, {'id': 'download_video', 'label': 'download_video', 'level': 2, 'title': '"""\n    download video\n    :param _: Request request\n    :param file_path: video file path, eg: /cd1727ed-3473-42a2-a7da-4faafafec72b/final-1.mp4\n    :return: video file'}, {'id': 'exception_handler', 'label': 'exception_handler', 'level': 2, 'title': '"""Handle exceptions by returning a JSON response.\n\n    This function takes an HTTP request and an exception as input, and it\n    constructs a JSON response with the appropriate status code and content\n    based on the exception details. It utilizes a utility function to format\n    the response content, ensuring that the client receives a structured\n    error message.\n\n    Args:\n        request (Request): The HTTP request object that triggered the exception.\n        e (HttpException): The exception object containing details about the error.\n\n    Returns:\n        JSONResponse: A JSON response with the status code and error message.'}, {'id': 'start', 'label': 'start', 'level': 2, 'title': '"""Start the video processing task.\n\n    This function orchestrates the video processing workflow by generating a\n    script, terms, audio, subtitles, and final videos based on the provided\n    parameters. It updates the task state throughout the process and allows\n    for stopping at various stages of the workflow. The function handles\n    different video sources and manages progress updates to reflect the\n    current state of the task.\n\n    Args:\n        task_id (str): The unique identifier for the task.\n        params (VideoParams): The parameters required for video processing.\n        stop_at (str?): The stage at which to stop processing.\n            Can be one of "video", "script", "terms", "audio", "subtitle", or\n            "materials". Defaults to "video".\n\n    Returns:\n        dict: A dictionary containing the results of the processing at the specified\n            stop stage, which may include:\n            - script (str): The generated video script.\n            - terms (str): The generated video terms.\n            - audio_file (str): The path to the generated audio file.\n            - audio_duration (float): The duration of the generated audio.\n            - subtitle_path (str): The path to the generated subtitle file.\n            - materials (list): The list of downloaded video materials.'}, {'id': 'toggle_set', 'label': 'toggle_set', 'level': 2, 'title': '"""Generate fake response for a given user ID.\n\n    Args:\n        user_id (str): The user ID for which the fake response is generated.\n\n    Returns:\n        str: The fake response for the specified user ID.'}, {'id': 'generate_final_videos', 'label': 'generate_final_videos', 'level': 2, 'title': '"""Generate final video files from downloaded videos and audio.\n\n    This function combines a list of downloaded videos into a single video\n    file for each specified video count. It utilizes the provided audio file\n    and subtitles to generate the final output videos. The progress of the\n    video generation is updated throughout the process. The function returns\n    the paths of the final generated videos and the combined video files.\n\n    Args:\n        task_id (str): The identifier for the current task.\n        params (Params): An object containing parameters for video generation,\n            including video count, aspect ratio, clip duration,\n            and thread count.\n        downloaded_videos (list): A list of paths to the downloaded video files.\n        audio_file (str): The path to the audio file to be used in the final videos.\n        subtitle_path (str): The path to the subtitle file to be included in the final videos.\n\n    Returns:\n        tuple: A tuple containing two lists:\n            - list: Paths to the final generated video files.\n            - list: Paths to the combined video files.'}, {'id': 'get_task', 'label': 'get_task', 'level': 2, 'title': '"""Retrieve a task from the Redis database using its task ID.\n\n        This function fetches the task data associated with the given task ID\n        from a Redis database. If the task data is found, it decodes the keys\n        from bytes to strings and converts the values to their original types\n        before returning the task as a dictionary. If no task data is found, it\n        returns None.\n\n        Args:\n            task_id (str): The unique identifier for the task to be retrieved.\n\n        Returns:\n            dict or None: A dictionary containing the task data if found,\n            or None if no task data exists for the given task ID.'}, {'id': 'get_bgm_file', 'label': 'get_bgm_file', 'level': 2, 'title': '"""Retrieve a background music (BGM) file based on the specified type.\n\n    This function checks if a BGM type is provided and returns a\n    corresponding music file. If a specific BGM file is given and it exists,\n    that file is returned. If the BGM type is "random", it searches for all\n    MP3 files in the designated song directory and randomly selects one to\n    return. If no valid BGM type is provided or no files are found, an empty\n    string is returned.\n\n    Args:\n        bgm_type (str): The type of BGM to retrieve. Defaults to "random".\n        bgm_file (str): The specific BGM file to return if it exists. Defaults to an empty\n            string.\n\n    Returns:\n        str: The path to the selected BGM file or an empty string if no valid file is\n            found.'}, {'id': 'generate_video', 'label': 'generate_video', 'level': 2, 'title': '"""Generate a video by combining video, audio, and subtitles.\n\n    This function takes a video file, an audio file, and optional subtitles\n    to create a new video file. It handles the positioning and styling of\n    subtitles, adjusts audio levels, and manages the output settings. The\n    function also logs the process and handles background music if\n    specified.\n\n    Args:\n        video_path (str): The path to the input video file.\n        audio_path (str): The path to the input audio file.\n        subtitle_path (str): The path to the subtitle file.\n        output_file (str): The path where the output video file will be saved.\n        params (VideoParams): An object containing various parameters for video generation, such as\n            aspect ratio, font settings, volume levels, and subtitle options.'}, {'id': 'generate_audio', 'label': 'generate_audio', 'level': 2, 'title': '"""Generate audio from a video script using text-to-speech.\n\n    This function generates an audio file from the provided video script\n    using a text-to-speech service. It logs the process and checks for\n    potential issues such as language mismatches or network availability. If\n    the audio generation fails, it updates the task state to failed and logs\n    an error message with troubleshooting tips. If successful, it returns\n    the path to the generated audio file, its duration, and the sub_maker\n    object used for audio generation.\n\n    Args:\n        task_id (str): The identifier for the task being processed.\n        params (object): An object containing parameters for voice generation,\n            including voice name and rate.\n        video_script (str): The script that will be converted to audio.\n\n    Returns:\n        tuple: A tuple containing:\n            - str: The path to the generated audio file.\n            - int: The duration of the audio in seconds.\n            - object: The sub_maker object used for audio generation.'}, {'id': 'generate_subtitle', 'label': 'generate_subtitle', 'level': 2, 'title': '"""Generate subtitles for a video based on the provided parameters.\n\n    This function generates subtitles for a video by utilizing a specified\n    subtitle provider. It first checks if subtitles are enabled in the\n    parameters. If enabled, it attempts to create subtitles using the\n    designated provider (either "edge" or "whisper"). If the "edge" provider\n    fails to create the subtitle file, it falls back to using the "whisper"\n    provider. The generated subtitles are then corrected based on the video\n    script, and the path to the subtitle file is returned.\n\n    Args:\n        task_id (str): The identifier for the task.\n        params (object): An object containing parameters, including\n            whether subtitles are enabled.\n        video_script (str): The script of the video for reference.\n        sub_maker (object): An object responsible for creating subtitles.\n        audio_file (str): The path to the audio file associated with the video.\n\n    Returns:\n        str: The path to the generated subtitle file, or an empty string if\n            subtitles are not enabled or if the subtitle file is invalid.'}, {'id': 'validation_exception_handler', 'label': 'validation_exception_handler', 'level': 2, 'title': '"""Handle request validation exceptions.\n\n    This function is designed to handle exceptions that occur during request\n    validation. When a validation error is encountered, it constructs a JSON\n    response with a 400 status code, indicating that the request was\n    invalid. The response includes details about the validation errors that\n    occurred, allowing the client to understand what fields are required or\n    what issues were found in the request.\n\n    Args:\n        request (Request): The incoming request object that triggered\n            the validation error.\n        e (RequestValidationError): The exception raised during\n            request validation, containing details about the errors.\n\n    Returns:\n        JSONResponse: A JSON response with a status code of 400 and\n            a message indicating that fields are required, along with\n            the specific validation errors.'}, {'id': 'generate_terms', 'label': 'generate_terms', 'level': 2, 'title': '"""Generate search terms for stock videos based on the video subject.\n\n    This function generates a specified number of search terms related to a\n    given video subject. It constructs a prompt for a video search terms\n    generator and processes the response to extract relevant search terms.\n    The generated terms are expected to be in English and should include the\n    main subject of the video. The function retries the generation process\n    in case of failure and ensures that the output is a valid JSON array of\n    strings.\n\n    Args:\n        video_subject (str): The subject of the video for which search terms are to be generated.\n        video_script (str): The script of the video, which is not used in the output but may provide\n            context.\n        amount (int?): The number of search terms to generate. Defaults to 5.\n\n    Returns:\n        List[str]: A list of generated search terms related to the video subject.'}, {'id': 'combine_videos', 'label': 'combine_videos', 'level': 2, 'title': '"""Combine multiple video clips into a single video synchronized with an\n    audio file.\n\n    This function takes a list of video file paths and combines them into a\n    single video that is synchronized with the provided audio file. The\n    videos can be concatenated either sequentially or randomly, based on the\n    specified mode. Each video clip is split into segments of a maximum\n    duration defined by `max_clip_duration`, and the final output video is\n    resized to match the specified aspect ratio. The function also handles\n    audio synchronization, ensuring that the combined video matches the\n    length of the audio.\n\n    Args:\n        combined_video_path (str): The file path where the combined video will be saved.\n        video_paths (List[str]): A list of file paths for the video clips to be combined.\n        audio_file (str): The file path for the audio file to synchronize with the video.\n        video_aspect (VideoAspect?): The aspect ratio of the output video. Defaults to VideoAspect.portrait.\n        video_concat_mode (VideoConcatMode?): The mode for concatenating videos (sequential or random). Defaults to\n            VideoConcatMode.random.\n        max_clip_duration (int?): The maximum duration for each video clip segment in seconds. Defaults to\n            5.\n        threads (int?): The number of threads to use for writing the video file. Defaults to 2.\n\n    Returns:\n        str: The file path of the combined video.'}, {'id': 'cluster_6', 'label': 'azure_related', 'level': 1}, {'id': 'azure_tts_v2', 'label': 'azure_tts_v2', 'level': 2, 'title': ''}, {'id': 'azure_tts_v1', 'label': 'azure_tts_v1', 'level': 2, 'title': ''}, {'id': 'speech_synthesizer_word_boundary_cb', 'label': 'speech_synthesizer_word_boundary_cb', 'level': 2, 'title': ''}, {'id': 'get_all_azure_voices', 'label': 'get_all_azure_voices', 'level': 2, 'title': ''}, {'id': 'cluster_7', 'label': 'to_related', 'level': 1}, {'id': 'time_convert_seconds_to_hmsm', 'label': 'time_convert_seconds_to_hmsm', 'level': 2, 'title': ''}, {'id': 'to_resolution', 'label': 'to_resolution', 'level': 2, 'title': ''}, {'id': '_format_duration_to_offset', 'label': '_format_duration_to_offset', 'level': 2, 'title': ''}, {'id': 'text_to_srt', 'label': 'text_to_srt', 'level': 2, 'title': ''}, {'id': 'formatter', 'label': 'formatter', 'level': 2, 'title': '"""\n        1\n        00:00:00,000 --> 00:00:02,360\n        跑步是一项简单易行的运动'}, {'id': 'recognized', 'label': 'recognized', 'level': 2, 'title': ''}, {'id': '_format_text', 'label': '_format_text', 'level': 2, 'title': ''}, {'id': 'convert_rate_to_percent', 'label': 'convert_rate_to_percent', 'level': 2, 'title': ''}, {'id': 'cluster_8', 'label': 'dir_related', 'level': 1}, {'id': 'similarity', 'label': 'similarity', 'level': 2, 'title': ''}, {'id': 'create_audio', 'label': 'create_audio', 'level': 2, 'title': ''}, {'id': 'get_uuid', 'label': 'get_uuid', 'level': 2, 'title': ''}, {'id': 'song_dir', 'label': 'song_dir', 'level': 2, 'title': ''}, {'id': 'enqueue', 'label': 'enqueue', 'level': 2, 'title': ''}, {'id': 'resource_dir', 'label': 'resource_dir', 'level': 2, 'title': ''}, {'id': 'ping', 'label': 'ping', 'level': 2, 'title': ''}, {'id': 'public_dir', 'label': 'public_dir', 'level': 2, 'title': ''}, {'id': 'run', 'label': 'run', 'level': 2, 'title': ''}, {'id': 'tts', 'label': 'tts', 'level': 2, 'title': ''}, {'id': 'md5', 'label': 'md5', 'level': 2, 'title': ''}, {'id': 'task_dir', 'label': 'task_dir', 'level': 2, 'title': ''}, {'id': 'run_in_background', 'label': 'run_in_background', 'level': 2, 'title': ''}, {'id': 'create_video', 'label': 'create_video', 'level': 2, 'title': ''}, {'id': 'storage_dir', 'label': 'storage_dir', 'level': 2, 'title': ''}, {'id': 'delete_task', 'label': 'delete_task', 'level': 2, 'title': ''}, {'id': 'font_dir', 'label': 'font_dir', 'level': 2, 'title': ''}, {'id': 'root_dir', 'label': 'root_dir', 'level': 2, 'title': ''}, {'id': 'run_task', 'label': 'run_task', 'level': 2, 'title': ''}, {'id': '__init__', 'label': '__init__', 'level': 2, 'title': ''}, {'id': 'is_queue_empty', 'label': 'is_queue_empty', 'level': 2, 'title': ''}, {'id': 'startup_event', 'label': 'startup_event', 'level': 2, 'title': ''}, {'id': 'execute_task', 'label': 'execute_task', 'level': 2, 'title': ''}, {'id': 'get_task_id', 'label': 'get_task_id', 'level': 2, 'title': ''}, {'id': 'get_response', 'label': 'get_response', 'level': 2, 'title': ''}, {'id': 'task_done', 'label': 'task_done', 'level': 2, 'title': ''}, {'id': 'parse_extension', 'label': 'parse_extension', 'level': 2, 'title': ''}, {'id': 'is_azure_v2_voice', 'label': 'is_azure_v2_voice', 'level': 2, 'title': ''}, {'id': 'get_audio_duration', 'label': 'get_audio_duration', 'level': 2, 'title': '"""\n    获取音频时长'}, {'id': 'new_router', 'label': 'new_router', 'level': 2, 'title': ''}, {'id': 'create_queue', 'label': 'create_queue', 'level': 2, 'title': ''}, {'id': 'is_user_in_set', 'label': 'is_user_in_set', 'level': 2, 'title': ''}, {'id': 'str_contains_punctuation', 'label': 'str_contains_punctuation', 'level': 2, 'title': ''}, {'id': 'shutdown_event', 'label': 'shutdown_event', 'level': 2, 'title': ''}, {'id': 'parse_voice_name', 'label': 'parse_voice_name', 'level': 2, 'title': ''}, {'id': 'dequeue', 'label': 'dequeue', 'level': 2, 'title': ''}, {'id': 'cluster_9', 'label': 'bgm_related', 'level': 1}, {'id': 'get_bgm_list', 'label': 'get_bgm_list', 'level': 2, 'title': ''}, {'id': 'upload_bgm_file', 'label': 'upload_bgm_file', 'level': 2, 'title': ''}]);
        const edges = new vis.DataSet([{'from': 'root', 'to': 'cluster_0'}, {'from': 'cluster_0', 'to': 'get_api_key'}, {'from': 'cluster_0', 'to': 'load_locales'}, {'from': 'cluster_0', 'to': 'get_system_locale'}, {'from': 'root', 'to': 'cluster_1'}, {'from': 'cluster_1', 'to': 'generate_video_script'}, {'from': 'cluster_1', 'to': 'search_videos_pixabay'}, {'from': 'cluster_1', 'to': 'save_video'}, {'from': 'cluster_1', 'to': 'search_videos_pexels'}, {'from': 'cluster_1', 'to': 'download_videos'}, {'from': 'cluster_1', 'to': 'file_to_subtitles'}, {'from': 'cluster_1', 'to': 'stream_video'}, {'from': 'cluster_1', 'to': 'generate_video_terms'}, {'from': 'cluster_1', 'to': 'delete_video'}, {'from': 'cluster_1', 'to': 'file_iterator'}, {'from': 'root', 'to': 'cluster_2'}, {'from': 'cluster_2', 'to': 'save_config'}, {'from': 'cluster_2', 'to': 'file_to_uri'}, {'from': 'root', 'to': 'cluster_3'}, {'from': 'cluster_3', 'to': 'check_queue'}, {'from': 'cluster_3', 'to': 'verify_token'}, {'from': 'root', 'to': 'cluster_4'}, {'from': 'cluster_4', 'to': 'levenshtein_distance'}, {'from': 'cluster_4', 'to': 'correct'}, {'from': 'cluster_4', 'to': 'load_config'}, {'from': 'cluster_4', 'to': '__init_logger'}, {'from': 'cluster_4', 'to': 'serialize'}, {'from': 'cluster_4', 'to': 'format_record'}, {'from': 'cluster_4', 'to': 'to_json'}, {'from': 'cluster_4', 'to': '_do'}, {'from': 'cluster_4', 'to': 'add_task'}, {'from': 'cluster_4', 'to': 'match_line'}, {'from': 'cluster_4', 'to': 'create'}, {'from': 'cluster_4', 'to': 'create_task'}, {'from': 'cluster_4', 'to': 'split_string_by_punctuations'}, {'from': 'root', 'to': 'cluster_5'}, {'from': 'cluster_5', 'to': 'create_subtitle'}, {'from': 'cluster_5', 'to': 'format_response'}, {'from': 'cluster_5', 'to': 'preprocess_video'}, {'from': 'cluster_5', 'to': '_generate_response'}, {'from': 'cluster_5', 'to': 'save_script_data'}, {'from': 'cluster_5', 'to': 'update_task'}, {'from': 'cluster_5', 'to': 'get_application'}, {'from': 'cluster_5', 'to': 'get_text_size'}, {'from': 'cluster_5', 'to': '_convert_to_original_type'}, {'from': 'cluster_5', 'to': 'generate_script'}, {'from': 'cluster_5', 'to': 'create_text_clip'}, {'from': 'cluster_5', 'to': 'get_video_materials'}, {'from': 'cluster_5', 'to': 'wrap_text'}, {'from': 'cluster_5', 'to': 'toogle_openai_usage'}, {'from': 'cluster_5', 'to': 'download_video'}, {'from': 'cluster_5', 'to': 'exception_handler'}, {'from': 'cluster_5', 'to': 'start'}, {'from': 'cluster_5', 'to': 'toggle_set'}, {'from': 'cluster_5', 'to': 'generate_final_videos'}, {'from': 'cluster_5', 'to': 'get_task'}, {'from': 'cluster_5', 'to': 'get_bgm_file'}, {'from': 'cluster_5', 'to': 'generate_video'}, {'from': 'cluster_5', 'to': 'generate_audio'}, {'from': 'cluster_5', 'to': 'generate_subtitle'}, {'from': 'cluster_5', 'to': 'validation_exception_handler'}, {'from': 'cluster_5', 'to': 'generate_terms'}, {'from': 'cluster_5', 'to': 'combine_videos'}, {'from': 'root', 'to': 'cluster_6'}, {'from': 'cluster_6', 'to': 'azure_tts_v2'}, {'from': 'cluster_6', 'to': 'azure_tts_v1'}, {'from': 'cluster_6', 'to': 'speech_synthesizer_word_boundary_cb'}, {'from': 'cluster_6', 'to': 'get_all_azure_voices'}, {'from': 'root', 'to': 'cluster_7'}, {'from': 'cluster_7', 'to': 'time_convert_seconds_to_hmsm'}, {'from': 'cluster_7', 'to': 'to_resolution'}, {'from': 'cluster_7', 'to': '_format_duration_to_offset'}, {'from': 'cluster_7', 'to': 'text_to_srt'}, {'from': 'cluster_7', 'to': 'formatter'}, {'from': 'cluster_7', 'to': 'recognized'}, {'from': 'cluster_7', 'to': '_format_text'}, {'from': 'cluster_7', 'to': 'convert_rate_to_percent'}, {'from': 'root', 'to': 'cluster_8'}, {'from': 'cluster_8', 'to': 'similarity'}, {'from': 'cluster_8', 'to': 'create_audio'}, {'from': 'cluster_8', 'to': 'get_uuid'}, {'from': 'cluster_8', 'to': 'song_dir'}, {'from': 'cluster_8', 'to': 'enqueue'}, {'from': 'cluster_8', 'to': 'resource_dir'}, {'from': 'cluster_8', 'to': 'ping'}, {'from': 'cluster_8', 'to': 'public_dir'}, {'from': 'cluster_8', 'to': 'run'}, {'from': 'cluster_8', 'to': 'tts'}, {'from': 'cluster_8', 'to': 'md5'}, {'from': 'cluster_8', 'to': 'task_dir'}, {'from': 'cluster_8', 'to': 'run_in_background'}, {'from': 'cluster_8', 'to': 'create_video'}, {'from': 'cluster_8', 'to': 'storage_dir'}, {'from': 'cluster_8', 'to': 'delete_task'}, {'from': 'cluster_8', 'to': 'font_dir'}, {'from': 'cluster_8', 'to': 'root_dir'}, {'from': 'cluster_8', 'to': 'run_task'}, {'from': 'cluster_8', 'to': '__init__'}, {'from': 'cluster_8', 'to': 'is_queue_empty'}, {'from': 'cluster_8', 'to': 'startup_event'}, {'from': 'cluster_8', 'to': 'execute_task'}, {'from': 'cluster_8', 'to': 'get_task_id'}, {'from': 'cluster_8', 'to': 'get_response'}, {'from': 'cluster_8', 'to': 'task_done'}, {'from': 'cluster_8', 'to': 'parse_extension'}, {'from': 'cluster_8', 'to': 'is_azure_v2_voice'}, {'from': 'cluster_8', 'to': 'get_audio_duration'}, {'from': 'cluster_8', 'to': 'new_router'}, {'from': 'cluster_8', 'to': 'create_queue'}, {'from': 'cluster_8', 'to': 'is_user_in_set'}, {'from': 'cluster_8', 'to': 'str_contains_punctuation'}, {'from': 'cluster_8', 'to': 'shutdown_event'}, {'from': 'cluster_8', 'to': 'parse_voice_name'}, {'from': 'cluster_8', 'to': 'dequeue'}, {'from': 'root', 'to': 'cluster_9'}, {'from': 'cluster_9', 'to': 'get_bgm_list'}, {'from': 'cluster_9', 'to': 'upload_bgm_file'}]);
        
        const container = document.getElementById('mindmap');
        const data = {
            nodes: nodes,
            edges: edges
        };
        const options = {
            layout: {
                hierarchical: {
                    direction: 'UD',
                    sortMethod: 'directed',
                    levelSeparation: 150
                }
            },
            physics: {
                hierarchicalRepulsion: {
                    centralGravity: 0.0,
                    springLength: 100,
                    springConstant: 0.01,
                    nodeDistance: 120
                },
                solver: 'hierarchicalRepulsion'
            }
        };
        
        const network = new vis.Network(container, data, options);
    </script>
</body>
</html>
